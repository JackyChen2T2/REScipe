{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "REScipe.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqj46gv1qf/tCR4pIhOjjT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JackyChen2T2/REScipe/blob/main/REScipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vh4BtR0qeAuC"
      },
      "source": [
        "# for loading google drive files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# for data cleaning\n",
        "import pandas as pd\n",
        "\n",
        "# for tokenizing english words\n",
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "# for the option of using GloVe representation\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "import spacy\n",
        "!python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCd_B5JWlgoO"
      },
      "source": [
        "# flags\n",
        "XLSX_PATH = '/content/drive/My Drive/Colab Notebooks/Project_REScipe/data/total_data.xlsx'      # copy the path of the xlsx file in Path in Google Colab menu\n",
        "XLSX_COLUMN = ['rand_int_0', 'name', 'url', 'rand_int_1', 'size', 'ingredient', 'recipe', 'rand_int_2']\n",
        "ALL_DATA = False"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPFogLA7jM4g"
      },
      "source": [
        "===================== A =====================\n",
        "\n",
        "This section loads the excel file(.xlsx) into a Pandas Dataframe.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-92lgp7zidU-",
        "outputId": "7341a970-0e46-485b-be76-84f472ce6999",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# load the xlsx file from Google Drive to a Pandas Dataframe\n",
        "xlsx_total_data = pd.read_excel(XLSX_PATH, header=None, names=XLSX_COLUMN)\n",
        "\n",
        "print(xlsx_total_data)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       rand_int_0  ... rand_int_2\n",
            "0               0  ...     190001\n",
            "1               1  ...     190004\n",
            "2               2  ...     190015\n",
            "3               3  ...     190032\n",
            "4               4  ...     190060\n",
            "...           ...  ...        ...\n",
            "40333           7  ...     149842\n",
            "40334           8  ...     149844\n",
            "40335           9  ...     149846\n",
            "40336          10  ...     149855\n",
            "40337          11  ...     149896\n",
            "\n",
            "[40338 rows x 8 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJPNddBuu_bU"
      },
      "source": [
        "===================== B =====================\n",
        "\n",
        "This section saves recipe names (index 'name') from the Pandas Dataframe to a csv file in the same Google Drive folder.\n",
        "\n",
        "This file (total_name.csv) is a temporary dictionary for debugging topic modeling and LDA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPnS2-3Wrv6r",
        "outputId": "2140b36b-c089-4e9a-8290-17ba166621b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# extract the column of 'name' from the Pandas Dataframe\n",
        "csv_name = xlsx_total_data[['name']]\n",
        "# add an additional index column, in case that tokenization removes certain recipes\n",
        "csv_name['index'] = csv_name.index\n",
        "\n",
        "csv_path = '/'.join(XLSX_PATH.split(sep='/')[:-1]) + '/total_name.csv'\n",
        "csv_name.to_csv(csv_path)\n",
        "\n",
        "print(csv_name)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                             name  index\n",
            "0                             Winter Endive Salad      0\n",
            "1                        Stuffed Artichoke Hearts      1\n",
            "2                      Slow Cooker Moscow Chicken      2\n",
            "3      Slow Cooker Creole Black Beans and Sausage      3\n",
            "4              Champagne Sorbet with Berry Medley      4\n",
            "...                                           ...    ...\n",
            "40333                           Hawaiian Iced Tea  40333\n",
            "40334                    Belgian Endive au Gratin  40334\n",
            "40335                             Hot Cider Punch  40335\n",
            "40336    Hash Brown Casserole for the Slow Cooker  40336\n",
            "40337                       Samhain Pumpkin Bread  40337\n",
            "\n",
            "[40338 rows x 2 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZYWcatDhIb5"
      },
      "source": [
        "===================== C =====================\n",
        "\n",
        "This section loads total_name.csv and saves a tokenized version of this csv back.\n",
        "\n",
        "This file (token_name.csv) is used for topic modeling with LDA, and GloVe representation (optional)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNXDrsss9gZX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}